# Haithm Style Finetuning Configuration

base_model_name: "Qwen/Qwen2.5-3B-Instruct"

dataset_path_natural: "data/dataset_haithm_style_natural.jsonl"
dataset_path_prompts: "data/dataset_haithm_style_prompts.jsonl"
use_prompts_dataset: true

output_dir_base: "models/hva_haithm_style_lora"

hyperparameters:
  num_train_epochs: 3
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  max_grad_norm: 0.3
  warmup_ratio: 0.03
  max_seq_length: 2048
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
